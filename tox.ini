# tox (https://tox.readthedocs.io/) is a tool for running tests
# in multiple virtualenvs. This configuration file will run the
# test suite on all supported python versions. To use it, "pip install tox"
# and then run "tox" from this directory.

[tox]
isolated_build = true
allowlist_externals = poetry
skipsdist = true
envlist = setup, update, format, py39, indent, sort, dataclass, numpy, performance-latency-dumps, performance-latency-loads, graph-benchmark, performance-memory

[testenv]
allowlist_externals = poetry
commands = poetry run pytest

#[testenv:correctness]
#commands = 
#    poetry install --remove-untracked
#    poetry run test_correctness

[testenv:format]
commands = 
    poetry run autoflake --in-place --recursive --remove-all-unused-imports --ignore-init-module-imports .
    poetry run isort orjson_benchmark tests
    poetry run black -l 120 orjson_benchmark tests

[testenv:graph-benchmark]
commands = 
    poetry install --remove-untracked
    poetry run graph-boxplot
    poetry run graph-tabulate

[testenv:indent]
commands = 
    poetry install --remove-untracked
    - poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/indent/image --benchmark-autosave --benchmark-save-data --benchmark-json=doc/indent/benchmark.json --random-order "orjson_benchmark/benchmark_indent.py"

#[testenv:nonstr]
#commands = 
#    poetry install --remove-untracked
#    poetry run test_nonstr

[testenv:performance-latency-dumps]
commands = poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/performance/latency/image_dumps --benchmark-autosave --benchmark-save-data --benchmark-json=doc/performance/latency/benchmark_dumps.json --random-order "orjson_benchmark/benchmark_dumps.py"

[testenv:performance-latency-empty]
commands = poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/performance/latency/image_empty --benchmark-json=doc/performance/latency/benchmark_empty.json --random-order "orjson_benchmark/benchmark_empty.py"

[testenv:performance-latency-loads]
commands = poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/performance/latency/image_loads --benchmark-autosave --benchmark-json=doc/performance/latency/benchmark_loads.json --benchmark-save-data --random-order "orjson_benchmark/benchmark_loads.py"

[testenv:performance-memory]
commands = 
    poetry install --remove-untracked
    poetry run test_memory

[testenv:dataclass]
commands = 
    poetry install --remove-untracked
    - poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/types/dataclass/image --benchmark-autosave --benchmark-save-data --benchmark-json=doc/types/dataclass/benchmark.json --random-order "orjson_benchmark/benchmark_dataclass.py"

[testenv:numpy]
commands = 
    poetry install --remove-untracked
    poetry run test_numpy int32
    poetry run test_numpy float64
    poetry run test_numpy bool
    poetry run test_numpy int8
    poetry run test_numpy uint8

[testenv:setup]
commands = poetry install --remove-untracked

[testenv:sort]
commands = 
    poetry install --remove-untracked
    poetry run pytest --verbose --benchmark-min-time=1 --benchmark-max-time=5 --benchmark-disable-gc --benchmark-histogram=doc/sorting/image --benchmark-autosave --benchmark-save-data --benchmark-json=doc/sorting/benchmark.json --random-order "orjson_benchmark/benchmark_sorting.py"

[testenv:update]
commands = poetry update

# NOT WORKING
#[pytest]
#verbose = true
#benchmark-min-time = 1
#benchmark-max-time = 5
#benchmark-disable-gc = true
#benchmark-autosave = true
#benchmark-save-data = true
#random-order = true
